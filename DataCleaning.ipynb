{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panama Papers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_panama = pd.read_csv(data_folder + 'panama_papers.edges.csv', dtype='unicode')\n",
    "edges_panama = edges_panama.dropna(axis = 1, how = 'all')\n",
    "\n",
    "addresses_panama = pd.read_csv(data_folder + 'panama_papers.nodes.address.csv')\n",
    "addresses_panama = addresses_panama.dropna(axis = 1, how = 'all')\n",
    "\n",
    "entities_panama = pd.read_csv(data_folder + 'panama_papers.nodes.entity.csv', dtype='unicode')\n",
    "entities_panama = entities_panama.dropna(axis = 1, how = 'all')\n",
    "\n",
    "intermediaries_panama = pd.read_csv(data_folder + 'panama_papers.nodes.intermediary.csv')\n",
    "intermediaries_panama = intermediaries_panama.dropna(axis = 1, how = 'all')\n",
    "\n",
    "officers_panama = pd.read_csv(data_folder + 'panama_papers.nodes.officer.csv')\n",
    "officers_panama = officers_panama.dropna(axis = 1, how = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paradise Papers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_paradise = pd.read_csv(data_folder + 'paradise_papers.edges.csv', dtype='unicode')\n",
    "edges_paradise = edges_panama.dropna(axis = 1, how = 'all')\n",
    "\n",
    "addresses_paradise = pd.read_csv(data_folder + 'paradise_papers.nodes.address.csv')\n",
    "addresses_paradise = addresses_paradise.dropna(axis = 1, how = 'all')\n",
    "\n",
    "entities_paradise = pd.read_csv(data_folder + 'paradise_papers.nodes.entity.csv', dtype='unicode')\n",
    "entities_paradise = entities_paradise.dropna(axis = 1, how = 'all')\n",
    "\n",
    "intermediaries_paradise = pd.read_csv(data_folder + 'paradise_papers.nodes.intermediary.csv')\n",
    "intermediaries_paradise = intermediaries_paradise.dropna(axis = 1, how = 'all')\n",
    "\n",
    "officers_paradise = pd.read_csv(data_folder + 'paradise_papers.nodes.officer.csv')\n",
    "officers_paradise = officers_paradise.dropna(axis = 1, how = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offshore Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_offshore = pd.read_csv(data_folder + 'offshore_leaks.edges.csv', dtype='unicode')\n",
    "edges_offshore = edges_offshore.dropna(axis = 1, how = 'all')\n",
    "\n",
    "addresses_offshore = pd.read_csv(data_folder + 'offshore_leaks.nodes.address.csv')\n",
    "addresses_offshore = addresses_offshore.dropna(axis = 1, how = 'all')\n",
    "\n",
    "entities_offshore = pd.read_csv(data_folder + 'offshore_leaks.nodes.entity.csv', dtype='unicode')\n",
    "entities_offshore = entities_offshore.dropna(axis = 1, how = 'all')\n",
    "\n",
    "intermediaries_offshore = pd.read_csv(data_folder + 'offshore_leaks.nodes.intermediary.csv')\n",
    "intermediaries_offshore = intermediaries_offshore.dropna(axis = 1, how = 'all')\n",
    "\n",
    "officers_offshore = pd.read_csv(data_folder + 'offshore_leaks.nodes.officer.csv')\n",
    "officers_offshore = officers_offshore.dropna(axis = 1, how = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bahamas_leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_bahamas = pd.read_csv(data_folder + 'bahamas_leaks.edges.csv', dtype='unicode')\n",
    "edges_bahamas = edges_bahamas.dropna(axis = 1, how = 'all')\n",
    "\n",
    "addresses_bahamas = pd.read_csv(data_folder + 'bahamas_leaks.nodes.address.csv')\n",
    "addresses_bahamas = addresses_bahamas.dropna(axis = 1, how = 'all')\n",
    "\n",
    "entities_bahamas = pd.read_csv(data_folder + 'bahamas_leaks.nodes.entity.csv', dtype='unicode')\n",
    "entities_bahamas = entities_bahamas.dropna(axis = 1, how = 'all')\n",
    "\n",
    "intermediaries_bahamas = pd.read_csv(data_folder + 'bahamas_leaks.nodes.intermediary.csv')\n",
    "intermediaries_bahamas = intermediaries_bahamas.dropna(axis = 1, how = 'all')\n",
    "\n",
    "officers_bahamas = pd.read_csv(data_folder + 'bahamas_leaks.nodes.officer.csv')\n",
    "officers_bahamas = officers_bahamas.dropna(axis = 1, how = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I renamed node_1 and node_2 in order to be able to concatinate with other dataframes\n",
    "edges_bahamas.rename(columns={'node_1':'START_ID', 'node_2':'END_ID', 'rel_type': 'TYPE'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges  = pd.concat([edges_panama, edges_bahamas, edges_offshore, edges_paradise], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_panama['node_type'] = \"adresse\"\n",
    "entities_panama['node_type'] = \"entity\"\n",
    "officers_panama['node_type'] = 'officers'\n",
    "intermediaries_panama['node_type'] = 'intermediaire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_bahamas['node_type'] = \"adresse\"\n",
    "entities_bahamas['node_type'] = \"entity\"\n",
    "officers_bahamas['node_type'] = 'officers'\n",
    "intermediaries_bahamas['node_type'] = 'intermediaire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_offshore['node_type'] = \"adresse\"\n",
    "entities_offshore['node_type'] = \"entity\"\n",
    "officers_offshore['node_type'] = 'officers'\n",
    "intermediaries_offshore['node_type'] = 'intermediaire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_paradise['node_type'] = \"adresse\"\n",
    "entities_paradise['node_type'] = \"entity\"\n",
    "officers_paradise['node_type'] = 'officers'\n",
    "intermediaries_paradise['node_type'] = 'intermediaire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses  = pd.concat([addresses_panama, addresses_bahamas, addresses_offshore, addresses_paradise], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities  = pd.concat([entities_panama, entities_bahamas, entities_offshore,entities_paradise], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officers  = pd.concat([officers_panama, officers_bahamas, officers_offshore,officers_paradise], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediaries = pd.concat([intermediaries_panama, intermediaries_bahamas, intermediaries_offshore,intermediaries_paradise], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning dataframe, \n",
    "**We will focus our analysis on countries so rows that do not contain the country or the country code will be dropped**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the country code is NaN the country name is NaN too\n",
    "entities = entities[entities['countries'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START_ID and END_ID in edges represent countries, so we will drop rows if one them is NaN\n",
    "edges = edges[edges['START_ID'].notnull()]\n",
    "edges = edges[edges['END_ID'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After merging edges from seperate datasets we noticed some duplicate values in edges dataframe, so we are going to avoid having wrong statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows in edges =  0\n"
     ]
    }
   ],
   "source": [
    "print('Number of duplicated rows in edges = ',len(edges[edges.duplicated()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping duplicates\n",
    "edges = edges.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the country code is NaN the country name is NaN too\n",
    "intermediaries = intermediaries[intermediaries['countries'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the country code is NaN the country name is NaN too\n",
    "officers = officers[officers['countries'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = addresses[addresses['countries'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We noticed that there is some rows with multiple countries(China;Hong Kong .....), in order to keep our dataframe consistent we will perfom en expansion of those columns** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Saint Kitts and Nevis', 'British Virgin Islands',\n",
       "       'Saint Vincent and the Grenadines', 'Turks and Caicos Islands',\n",
       "       'Sint Maarten (Dutch part)', 'Central African Republic',\n",
       "       'British Virgin Islands;Cyprus',\n",
       "       'Not identified;British Virgin Islands',\n",
       "       'Singapore;British Virgin Islands',\n",
       "       'Cyprus;British Virgin Islands', 'United States;Not identified',\n",
       "       'Russia;British Virgin Islands', 'Not identified;Netherlands',\n",
       "       'Not identified;United States', 'British Virgin Islands;Russia',\n",
       "       'British Virgin Islands;Singapore',\n",
       "       'British Virgin Islands;United Kingdom',\n",
       "       'British Virgin Islands;Not identified',\n",
       "       'United Kingdom;Not identified',\n",
       "       'British Virgin Islands;Hong Kong'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can see below that there is some inconsistency such as : 'British Virgin Islands;Cyprus'\n",
    "entities[entities.countries.str.len()>20].countries.unique()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this function will take a dataframe, a column and split_chart, it will explode rows that contains the specific char and will return new dataframe \n",
    "'''\n",
    "def explode(df, col, split_char):\n",
    "    return df.set_index(df.columns.drop(col,1).tolist())[col].str.split(split_char,expand=True).stack().reset_index().rename(columns={0:col}).loc[:, df.columns]\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = explode(entities, \"countries\", ';' )\n",
    "entities = entities[entities['countries'] != 'XXX']\n",
    "entities.drop(['country_codes'], inplace= True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediaries = explode(intermediaries, \"countries\", ';')\n",
    "intermediaries = intermediaries[intermediaries['countries'] != 'XXX']\n",
    "intermediaries.drop(['country_codes'], inplace= True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officers = explode(officers, 'countries', ';')\n",
    "officers = officers[officers['countries'] != 'XXX']\n",
    "officers.drop(['country_codes'], inplace= True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete non identified countries\n",
    "entities = entities[entities['countries'] != 'Not identified']\n",
    "intermediaries = intermediaries[intermediaries['countries'] != 'Not identified']\n",
    "officers = officers[officers['countries'] != 'Not identified']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.to_csv(data_folder + 'data_cleaned/entities.csv', index = False)\n",
    "intermediaries.to_csv(data_folder + 'data_cleaned/intermediaries.csv', index = False)\n",
    "officers.to_csv(data_folder + 'data_cleaned/officers.csv', index = False)\n",
    "addresses.to_csv(data_folder + 'data_cleaned/addresses.csv', index = False)\n",
    "edges.to_csv(data_folder + 'data_cleaned/edges.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
