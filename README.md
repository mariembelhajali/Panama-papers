## Title: Study of the Biggest Leak in History
#### Abstract:

The Panama Papers involved hundred thousands of offshore accounts, millions of documents detailing top secret financial information were leaked in 2015 by an anonymous source. The files show how Mossack Fonsecaâ€™s clients were able to launder money, dodge sanctions, avoid taxes.  It is estimated that tax havens cost poor countries at least $170 billion in lost tax revenues each year making poorest people lose out and the inequality gap grow. There is a huge amount of data, our work will be to provide a detailed analysis of the dataset in order to capture unknown and find more hidden connections. Getting a closer view about the involved countries and the distribution of the papers  around the world. This will help goverments detect corrupt companies  and come together to agree on the tough coordinated action that is needed to end the era of tax havens, showing how Data science can do good acknowledging the efforts given by journalists.  

#### Researchs questions: 
- What are the most correpted countries? Does underdevolped/poorest countries are more affected by corruption?  
- what are the connections and there types between the officers, entities and intermediaries? Are there a commun intermediaries/entites?
- Are there any hidden patterns that will allow us to detect corruption?
- How is the evolution of corruption over the years? Is it increasing or decreasing? 

#### Dataset:
- Panama papers

#### Internal milestones up until milestone 2:
- Recongnize and visualize connections and relationships between people, organization, institutions and countires.
- Processing the data and cleaning it because we noticed some incoherencies(example: checking duplicated entries).
- Identify useful attributes and drop those that wont need next.
- model our dataset in a graph format and learn about the nodes connections(example: connected components) 

